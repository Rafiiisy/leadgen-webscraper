![LeadGen Architecture](assets/leadgen%20logo.png)


## ðŸ“Œ Project Overview
LeadGen RAG Web Scraper is a tool designed to generate structured, insightful information from any public domain using Retrieval-Augmented Generation (RAG). It is tailored for lead generation tasks such as extracting company missions, services, and call-to-actions from websites, and organizing them into task-specific tables per domain.

---

## ðŸŽ¯ Goals & Missions
- **Simplify web-based lead intelligence** through an easy-to-use UI.
- **Support automated, explainable insights** powered by LLMs.
- **Allow domain-specific task evaluation**, enabling marketing teams, researchers, and analysts to retrieve targeted website summaries.
- **Offer performance diagnostics** to evaluate scraping robustness, LLM quality, and retrieval effectiveness.

---

## âœ¨ Novelties Compared to Existing Tools
| Feature | LeadGen Scraper | CohesiveAI / Other Scrapers |
|--------|------------------|-----------------------------|
| Per-domain task tables | âœ… | âŒ |
| Built-in insight evaluation dashboard | âœ… | âŒ |
| Hybrid retrieval (BM25 + FAISS) | âœ… | Limited |
| Manual + automatic domain input | âœ… | âœ… |
| Streamlit UI + persistent state | âœ… | Varies |
| Emphasis on interpretability | âœ… | âŒ |

---

## ðŸ› ï¸ Tech Stack & Rationale

| Component | Tool | Reasoning |
|----------|------|-----------|
| **Frontend** | Streamlit | Simple yet powerful for rapid dashboard development |
| **Scraping** | Cloudscraper, BeautifulSoup, Selenium | Handles both static and JS-heavy websites |
| **LLM Access** | HuggingFace / Local Model API | Cost-effective and controllable model deployment |
| **Retrieval** | FAISS + BM25 (HybridRetriever) | Combines vector similarity and keyword relevance |
| **Data Storage** | Streamlit Session State (in-memory) | Suitable for ephemeral, per-session task tables |

---

## ðŸ—ï¸ Architecture Diagram
![LeadGen Architecture](assets/leadgen%20arc.png)


---

## ðŸ”„ Workflow

1. **User adds a domain** via UI â†’ Creates a domain-specific task table.
2. **User adds a task** (e.g., "What is the mission?").
3. **System scrapes** the webpage and falls back to Selenium if needed.
4. **Chunks generated** from webpage text.
5. **HybridRetriever** selects relevant chunks using BM25 + FAISS.
6. **LLM** generates an answer based on prompt + chunks.
7. **Answer is stored** in the domain's table.
8. **(Optional)** Evaluation dashboard benchmarks runtime, insight quality, retrieval quality, and scraping robustness.

---

## ðŸ¤ª Evaluation Dashboard

### 1. âš¡ Runtime
- Tracks durations for scraping, fallback, LLM response, and overall turnaround.

### 2. ðŸ§  Insight Quality (Auto-evaluated)
- **Relevance**: Do output words overlap with task keywords?
- **Specificity**: Does the answer use actual tokens from the site?
- **Faithfulness**: Do phrases match retrieved chunks?

### 3. ðŸ” Retrieval Quality
- **Chunk Matching**: Are retrieved chunks semantically relevant?
- **Chunk Diversity**: Do chunks cover diverse sections or just repeat?

### 4. ðŸ§ª Scraping Robustness
- Verifies if fallback is triggered.
- Logs site types, status, and notes.

---

## âš™ï¸ Setup Instructions

### ðŸ“ Clone the repository
```bash
git clone https://github.com/Rafiiisy/leadgen-rag-scraper.git
cd leadgen-rag-scraper
```

### ðŸ Create virtual environment
```bash
python3 -m venv myenv
source myenv/bin/activate
```

### ðŸ“¦ Install dependencies
```bash
pip install -r requirements.txt
```

### ðŸ“„ Configure API Keys (Optional)
Create a `.env` file:
```
PYTHONPATH=.
HUGGINGFACE_API_KEY=your_key_here
```

### ðŸš€ Run the App
```bash
python -m streamlit run app.py
```

---

## ðŸ“ Project Structure
```
.
â”œâ”€â”€ app.py                  # Streamlit app UI
â”œâ”€â”€ config.py               # API config
â”œâ”€â”€ style.css               # UI styles
â”œâ”€â”€ requirements.txt        # All dependencies
â”œâ”€â”€ .env                    # Your secrets (gitignored)
â”œâ”€â”€ assets/                 # Logo and images
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ scraper.py          # Website parser & tagger
â”‚   â”œâ”€â”€ vectorstore.py      # Hybrid retriever (BM25 + FAISS)
â”‚   â”œâ”€â”€ llm.py              # LLM inference using HF API (FLAN-T5)
â”‚   â”œâ”€â”€ rag_runner.py       # Scrape â†’ retrieve â†’ prompt â†’ answer
â”‚   â”œâ”€â”€ domain_inserter.py  # Domain table pipeline
â”‚   â”œâ”€â”€ storage.py          # Save/load raw chunks
â”‚   â”œâ”€â”€ embeddings.py       # Sentence transformer
â”‚   â”œâ”€â”€ utils.py            # Helper functions
â”‚   â”œâ”€â”€ evaluation.py       # Heuristic scoring methods
```

---

## ðŸš€ Model Details
This project uses `google/flan-t5-large` for both:
- LLM1: Categorization of raw website content into sections (e.g., About, Services)
- LLM2: Generating task-specific insights from categorized content

Model selected for its strong zero-shot performance and instruction-following abilities. Citation:
> Chung, H., Hou, L., Longpre, S., et al. (2022). *Scaling Instruction-Finetuned Language Models*. arXiv. https://doi.org/10.48550/arxiv.2210.11416

---

## ðŸš€ Future Improvements
- [ ] Add PDF and image parsing (OCR for flyers)
- [ ] Persistent storage (SQLite / Supabase backend)
- [ ] PDF/CSV export of task tables
- [ ] User authentication for multi-user support
- [ ] Customize prompt templates per domain type
- [ ] LLM caching & retry analytics

---

## ðŸ“¬ Contact & Contributions
Feel free to fork or submit issues! Created by [@Rafiiisy](https://github.com/Rafiiisy) for exploration and research in lead generation tools using open-source LLMs.
